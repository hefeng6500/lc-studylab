# ç¬¬ 3 é˜¶æ®µæŠ€æœ¯å®ç°æ–‡æ¡£

## ğŸ“‹ å®ç°æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è®°å½•äº†ç¬¬ 3 é˜¶æ®µ LangGraph è‡ªå®šä¹‰å·¥ä½œæµçš„æŠ€æœ¯å®ç°ç»†èŠ‚ï¼ŒåŒ…æ‹¬è®¾è®¡å†³ç­–ã€å…³é”®ä»£ç å’Œé‡åˆ°çš„é—®é¢˜ã€‚

## ğŸ¯ æ ¸å¿ƒè®¾è®¡å†³ç­–

### 1. ä¸ºä»€ä¹ˆé€‰æ‹© LangGraphï¼Ÿ

**ä¼˜åŠ¿ï¼š**
- âœ… åŸç”Ÿæ”¯æŒæœ‰çŠ¶æ€å·¥ä½œæµ
- âœ… å†…ç½®æ£€æŸ¥ç‚¹æœºåˆ¶
- âœ… æ”¯æŒäººæœºäº¤äº’ï¼ˆinterruptï¼‰
- âœ… ä¸ LangChain æ— ç¼é›†æˆ
- âœ… æ”¯æŒæ¡ä»¶è·¯ç”±å’Œå¾ªç¯

**å¯¹æ¯”å…¶ä»–æ–¹æ¡ˆï¼š**
- **çº¯ LangChain LCEL**ï¼šç¼ºå°‘çŠ¶æ€ç®¡ç†å’Œæ£€æŸ¥ç‚¹
- **è‡ªå®šä¹‰çŠ¶æ€æœº**ï¼šéœ€è¦å¤§é‡æ‰‹åŠ¨ä»£ç 
- **Airflow/Prefect**ï¼šè¿‡äºé‡é‡çº§ï¼Œä¸é€‚åˆ LLM å·¥ä½œæµ

### 2. çŠ¶æ€æ¨¡å‹è®¾è®¡

ä½¿ç”¨ `TypedDict` è€Œé Pydantic `BaseModel` çš„åŸå› ï¼š

```python
class StudyFlowState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    # ...
```

**ä¼˜åŠ¿ï¼š**
- âœ… LangGraph åŸç”Ÿæ”¯æŒ TypedDict
- âœ… æ›´è½»é‡ï¼Œæ€§èƒ½æ›´å¥½
- âœ… æ”¯æŒ `Annotated` ç±»å‹æç¤º
- âœ… ä¸ LangGraph çš„æ¶ˆæ¯åˆå¹¶æœºåˆ¶å…¼å®¹

**å…³é”®æŠ€å·§ï¼š**

ä½¿ç”¨ `add_messages` æ³¨è§£è‡ªåŠ¨åˆå¹¶æ¶ˆæ¯å†å²ï¼š

```python
from langgraph.graph.message import add_messages

messages: Annotated[List[BaseMessage], add_messages]
```

è¿™æ ·æ¯æ¬¡æ›´æ–° messages æ—¶ï¼Œæ–°æ¶ˆæ¯ä¼šè‡ªåŠ¨è¿½åŠ åˆ°åˆ—è¡¨ï¼Œè€Œä¸æ˜¯æ›¿æ¢ã€‚

### 3. èŠ‚ç‚¹å®ç°æ¨¡å¼

æ‰€æœ‰èŠ‚ç‚¹éµå¾ªç»Ÿä¸€çš„æ¨¡å¼ï¼š

```python
def node_function(state: StudyFlowState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹å‡½æ•°
    
    Args:
        state: å½“å‰çŠ¶æ€ï¼ˆåªè¯»ï¼‰
        
    Returns:
        è¦æ›´æ–°çš„çŠ¶æ€å­—æ®µï¼ˆéƒ¨åˆ†æ›´æ–°ï¼‰
    """
    try:
        # 1. ä»çŠ¶æ€ä¸­è¯»å–è¾“å…¥
        input_data = state.get("some_field")
        
        # 2. æ‰§è¡Œä¸šåŠ¡é€»è¾‘
        result = process(input_data)
        
        # 3. è¿”å›è¦æ›´æ–°çš„å­—æ®µ
        return {
            "output_field": result,
            "current_step": "node_name",
            "updated_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {e}")
        return {
            "error": str(e),
            "error_node": "node_name"
        }
```

**å…³é”®ç‚¹ï¼š**
- èŠ‚ç‚¹å‡½æ•°æ¥æ”¶å®Œæ•´çŠ¶æ€ï¼Œä½†åªè¿”å›éœ€è¦æ›´æ–°çš„å­—æ®µ
- LangGraph ä¼šè‡ªåŠ¨åˆå¹¶è¿”å›å€¼åˆ°çŠ¶æ€ä¸­
- å§‹ç»ˆæ›´æ–° `current_step` å’Œ `updated_at` ç”¨äºè¿½è¸ª

### 4. æ£€æŸ¥ç‚¹ç­–ç•¥

ä½¿ç”¨ SQLite ä½œä¸ºæ£€æŸ¥ç‚¹å­˜å‚¨ï¼š

```python
from langgraph.checkpoint.sqlite import SqliteSaver

checkpointer = SqliteSaver.from_conn_string("checkpoints.db")
```

**ä¸ºä»€ä¹ˆé€‰æ‹© SQLiteï¼Ÿ**
- âœ… é›¶é…ç½®ï¼Œæ— éœ€é¢å¤–æœåŠ¡
- âœ… é€‚åˆå¼€å‘å’Œå°è§„æ¨¡éƒ¨ç½²
- âœ… æ”¯æŒäº‹åŠ¡å’Œå¹¶å‘æ§åˆ¶
- âœ… æ˜“äºå¤‡ä»½å’Œè¿ç§»

**ç”Ÿäº§ç¯å¢ƒå»ºè®®ï¼š**
- ä½¿ç”¨ PostgreSQL æ£€æŸ¥ç‚¹å­˜å‚¨
- å®šæœŸæ¸…ç†æ—§æ£€æŸ¥ç‚¹
- å®ç°æ£€æŸ¥ç‚¹å‹ç¼©

### 5. äººæœºäº¤äº’å®ç°

ä½¿ç”¨ `interrupt_before` åœ¨æŒ‡å®šèŠ‚ç‚¹å‰æš‚åœï¼š

```python
app = workflow.compile(
    checkpointer=checkpointer,
    interrupt_before=["human_review"]
)
```

**å·¥ä½œåŸç†ï¼š**

1. å·¥ä½œæµæ‰§è¡Œåˆ° `human_review` èŠ‚ç‚¹å‰æš‚åœ
2. ä¿å­˜å½“å‰çŠ¶æ€åˆ°æ£€æŸ¥ç‚¹
3. è¿”å›å½“å‰çŠ¶æ€ç»™è°ƒç”¨è€…
4. ç”¨æˆ·æäº¤ç­”æ¡ˆåï¼Œæ›´æ–°çŠ¶æ€
5. è°ƒç”¨ `invoke(None, config)` ç»§ç»­æ‰§è¡Œ

**å…³é”®ä»£ç ï¼š**

```python
# å¯åŠ¨å·¥ä½œæµï¼ˆä¼šåœ¨ human_review å‰æš‚åœï¼‰
result = app.invoke(initial_state, config)

# ç”¨æˆ·æäº¤ç­”æ¡ˆåï¼Œæ›´æ–°çŠ¶æ€
app.update_state(config, {"user_answers": answers})

# ç»§ç»­æ‰§è¡Œ
result = app.invoke(None, config)  # None è¡¨ç¤ºä¸æä¾›æ–°è¾“å…¥
```

## ğŸ” å…³é”®æŠ€æœ¯å®ç°

### 1. æ¡ä»¶è·¯ç”±å®ç°

æ ¹æ®å¾—åˆ†å†³å®šæ˜¯å¦é‡æ–°å‡ºé¢˜ï¼š

```python
def should_continue(state: StudyFlowState) -> Literal["retry", "end"]:
    """æ¡ä»¶è·¯ç”±å‡½æ•°"""
    should_retry = state.get("should_retry", False)
    retry_count = state.get("retry_count", 0)
    
    if should_retry and retry_count < 3:
        return "retry"
    return "end"

workflow.add_conditional_edges(
    "feedback",           # ä»å“ªä¸ªèŠ‚ç‚¹å‡ºå‘
    should_continue,      # è·¯ç”±å†³ç­–å‡½æ•°
    {
        "retry": "quiz_generator",  # è·¯ç”±ç›®æ ‡
        "end": END
    }
)
```

**ç±»å‹æç¤ºæŠ€å·§ï¼š**

ä½¿ç”¨ `Literal` ç¡®ä¿è¿”å›å€¼ç±»å‹å®‰å…¨ï¼š

```python
from typing import Literal

def router(state) -> Literal["option1", "option2"]:
    # ...
```

### 2. ç»“æ„åŒ–è¾“å‡ºå®ç°

ä½¿ç”¨ Pydantic æ¨¡å‹çº¦æŸ LLM è¾“å‡ºï¼š

```python
from pydantic import BaseModel, Field

class LearningPlanSchema(BaseModel):
    topic: str = Field(description="å­¦ä¹ ä¸»é¢˜")
    objectives: list[str] = Field(description="å­¦ä¹ ç›®æ ‡ï¼Œè‡³å°‘3ä¸ª")
    key_points: list[str] = Field(description="å…³é”®çŸ¥è¯†ç‚¹ï¼Œè‡³å°‘5ä¸ª")
    difficulty: str = Field(description="éš¾åº¦ï¼šbeginner/intermediate/advanced")
    estimated_time: int = Field(description="é¢„è®¡æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")

# ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
model = get_chat_model()
structured_model = model.with_structured_output(LearningPlanSchema)

response = structured_model.invoke([...])
# response æ˜¯ LearningPlanSchema å®ä¾‹
```

**ä¼˜åŠ¿ï¼š**
- âœ… ç¡®ä¿è¾“å‡ºæ ¼å¼æ­£ç¡®
- âœ… è‡ªåŠ¨éªŒè¯å­—æ®µç±»å‹
- âœ… æä¾›æ¸…æ™°çš„å­—æ®µæè¿°ç»™ LLM

### 3. è¯„åˆ†èŠ‚ç‚¹çš„æ··åˆç­–ç•¥

å¯¹ä¸åŒé¢˜å‹ä½¿ç”¨ä¸åŒçš„è¯„åˆ†ç­–ç•¥ï¼š

```python
def grading_node(state: StudyFlowState) -> Dict[str, Any]:
    for question in questions:
        q_type = question["type"]
        
        if q_type == "multiple_choice":
            # ç²¾ç¡®åŒ¹é…
            is_correct = user_answer.upper() == correct_answer.upper()
            points = points_possible if is_correct else 0
            
        elif q_type == "fill_blank":
            # å¿½ç•¥å¤§å°å†™çš„ç²¾ç¡®åŒ¹é…
            is_correct = user_answer.lower() == correct_answer.lower()
            points = points_possible if is_correct else 0
            
        elif q_type == "short_answer":
            # ä½¿ç”¨ LLM è¯„åˆ†
            grading_prompt = f"""è¯„ä¼°ç®€ç­”é¢˜...
            é¢˜ç›®ï¼š{question}
            æ ‡å‡†ç­”æ¡ˆï¼š{correct_answer}
            å­¦ç”Ÿç­”æ¡ˆï¼š{user_answer}
            æ»¡åˆ†ï¼š{points_possible}
            
            è¿”å›æ ¼å¼ï¼š
            å¾—åˆ†: X
            è¯„è¯­: XXX
            """
            response = model.invoke([{"role": "user", "content": grading_prompt}])
            # è§£æå¾—åˆ†...
```

**è®¾è®¡è€ƒè™‘ï¼š**
- å®¢è§‚é¢˜ç”¨è§„åˆ™è¯„åˆ†ï¼ˆå¿«é€Ÿã€å‡†ç¡®ï¼‰
- ä¸»è§‚é¢˜ç”¨ LLM è¯„åˆ†ï¼ˆçµæ´»ã€æ™ºèƒ½ï¼‰
- æä¾›è¯¦ç»†çš„è¯„åˆ†è§£æ

### 4. æµå¼è¾“å‡ºå®ç°

ä½¿ç”¨ `astream_events` å®ç°ç»†ç²’åº¦çš„æµå¼è¾“å‡ºï¼š

```python
async def stream_workflow(thread_id: str):
    app = get_study_flow_app()
    config = {"configurable": {"thread_id": thread_id}}
    
    async for event in app.astream_events(None, config, version="v2"):
        event_type = event.get("event")
        
        if event_type == "on_chain_start":
            yield f"data: {json.dumps({'type': 'node_start', 'node': event['name']})}\n\n"
        
        elif event_type == "on_chain_end":
            yield f"data: {json.dumps({'type': 'node_end', 'node': event['name']})}\n\n"
        
        elif event_type == "on_chat_model_stream":
            chunk = event.get("data", {}).get("chunk")
            if chunk and hasattr(chunk, "content"):
                yield f"data: {json.dumps({'type': 'token', 'content': chunk.content})}\n\n"
```

**äº‹ä»¶ç±»å‹ï¼š**
- `on_chain_start`: èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
- `on_chain_end`: èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ
- `on_chat_model_stream`: LLM ç”Ÿæˆ token
- `on_tool_start`: å·¥å…·è°ƒç”¨å¼€å§‹
- `on_tool_end`: å·¥å…·è°ƒç”¨ç»“æŸ

## ğŸ› é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: æ¶ˆæ¯å†å²é‡å¤

**ç—‡çŠ¶ï¼š** æ¯æ¬¡æ›´æ–°çŠ¶æ€æ—¶ï¼Œmessages åˆ—è¡¨è¢«å®Œå…¨æ›¿æ¢ï¼Œå¯¼è‡´å†å²ä¸¢å¤±ã€‚

**åŸå› ï¼š** æ²¡æœ‰ä½¿ç”¨ `add_messages` æ³¨è§£ã€‚

**è§£å†³ï¼š**
```python
# é”™è¯¯å†™æ³•
messages: List[BaseMessage]

# æ­£ç¡®å†™æ³•
messages: Annotated[List[BaseMessage], add_messages]
```

### é—®é¢˜ 2: æ£€æŸ¥ç‚¹æ•°æ®åº“é”å®š

**ç—‡çŠ¶ï¼š** å¹¶å‘æµ‹è¯•æ—¶å‡ºç° `database is locked` é”™è¯¯ã€‚

**åŸå› ï¼š** SQLite çš„å¹¶å‘é™åˆ¶ã€‚

**è§£å†³æ–¹æ¡ˆï¼š**
1. çŸ­æœŸï¼šæ¯ä¸ªæµ‹è¯•ä½¿ç”¨ä¸åŒçš„æ•°æ®åº“æ–‡ä»¶
2. é•¿æœŸï¼šè¿ç§»åˆ° PostgreSQL

```python
# ä¸ºæ¯ä¸ªæµ‹è¯•åˆ›å»ºç‹¬ç«‹çš„æ£€æŸ¥ç‚¹
checkpointer = SqliteSaver.from_conn_string(
    f"checkpoints_{thread_id}.db"
)
```

### é—®é¢˜ 3: ç»“æ„åŒ–è¾“å‡ºè§£æå¤±è´¥

**ç—‡çŠ¶ï¼š** LLM è¿”å›çš„ JSON æ ¼å¼ä¸ç¬¦åˆ Pydantic æ¨¡å‹ã€‚

**åŸå› ï¼š** æ¨¡å‹å®šä¹‰è¿‡äºä¸¥æ ¼ï¼Œæˆ– LLM ç†è§£ä¸å‡†ç¡®ã€‚

**è§£å†³æ–¹æ¡ˆï¼š**
1. ç®€åŒ– Pydantic æ¨¡å‹
2. åœ¨ Field ä¸­æä¾›æ›´æ¸…æ™°çš„æè¿°
3. æ·»åŠ ç¤ºä¾‹åˆ° prompt

```python
class QuizSchema(BaseModel):
    questions: List[QuizQuestionSchema] = Field(
        description="é¢˜ç›®åˆ—è¡¨ï¼Œè‡³å°‘5é¢˜ã€‚ç¤ºä¾‹ï¼š[{id: 'q1', type: 'multiple_choice', ...}]"
    )
```

### é—®é¢˜ 4: å·¥ä½œæµçŠ¶æ€ä¸ä¸€è‡´

**ç—‡çŠ¶ï¼š** æ¢å¤æ£€æŸ¥ç‚¹åï¼ŒæŸäº›å­—æ®µä¸º Noneã€‚

**åŸå› ï¼š** èŠ‚ç‚¹æ²¡æœ‰æ­£ç¡®æ›´æ–°æ‰€æœ‰å¿…è¦å­—æ®µã€‚

**è§£å†³æ–¹æ¡ˆï¼š**
- ç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹éƒ½æ›´æ–° `current_step` å’Œ `updated_at`
- ä½¿ç”¨é»˜è®¤å€¼å¤„ç†å¯é€‰å­—æ®µ

```python
def node(state: StudyFlowState) -> Dict[str, Any]:
    return {
        "result": ...,
        "current_step": "node_name",  # å¿…é¡»æ›´æ–°
        "updated_at": datetime.now().isoformat()  # å¿…é¡»æ›´æ–°
    }
```

## ğŸ“Š æ€§èƒ½åˆ†æ

### æ‰§è¡Œæ—¶é—´åˆ†æ

å…¸å‹å·¥ä½œæµçš„æ‰§è¡Œæ—¶é—´åˆ†å¸ƒï¼š

| èŠ‚ç‚¹ | å¹³å‡è€—æ—¶ | å æ¯” |
|------|---------|------|
| planner | 3-5s | 20% |
| retrieval | 1-2s | 10% |
| quiz_generator | 5-8s | 35% |
| human_review | N/A | - |
| grading | 2-4s | 15% |
| feedback | 3-5s | 20% |

**ä¼˜åŒ–å»ºè®®ï¼š**
1. ç¼“å­˜å­¦ä¹ è®¡åˆ’æ¨¡æ¿
2. å¹¶è¡Œæ‰§è¡Œæ£€ç´¢å’Œè§„åˆ’
3. ä½¿ç”¨æ›´å¿«çš„ embedding æ¨¡å‹

### å†…å­˜ä½¿ç”¨

- å•ä¸ªå·¥ä½œæµçŠ¶æ€ï¼šçº¦ 50-100 KB
- æ£€æŸ¥ç‚¹æ•°æ®åº“ï¼šæ¯ä¸ªä¼šè¯çº¦ 200-500 KB
- LLM ä¸Šä¸‹æ–‡ï¼šæ ¹æ®æ–‡æ¡£å¤§å°å˜åŒ–

**ä¼˜åŒ–å»ºè®®ï¼š**
1. é™åˆ¶æ£€ç´¢æ–‡æ¡£æ•°é‡
2. å®šæœŸæ¸…ç†æ—§æ£€æŸ¥ç‚¹
3. å‹ç¼©å¤§æ–‡æœ¬å­—æ®µ

## ğŸ”’ å®‰å…¨è€ƒè™‘

### 1. è¾“å…¥éªŒè¯

```python
class StartWorkflowRequest(BaseModel):
    user_question: str = Field(..., min_length=1, max_length=1000)
    thread_id: Optional[str] = Field(None, regex=r'^[a-zA-Z0-9_-]+$')
```

### 2. æ£€æŸ¥ç‚¹è®¿é—®æ§åˆ¶

- éªŒè¯ thread_id æ‰€æœ‰æƒ
- é™åˆ¶æ£€æŸ¥ç‚¹å†å²æŸ¥è¯¢æ·±åº¦
- å®šæœŸæ¸…ç†è¿‡æœŸæ£€æŸ¥ç‚¹

### 3. LLM è¾“å‡ºéªŒè¯

- ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºç¡®ä¿æ ¼å¼
- éªŒè¯ç”Ÿæˆçš„é¢˜ç›®æ•°é‡å’Œåˆ†å€¼
- æ£€æŸ¥ç­”æ¡ˆè§£æçš„åˆç†æ€§

## ğŸš€ æœªæ¥æ”¹è¿›æ–¹å‘

### 1. å¤šç”¨æˆ·æ”¯æŒ

- æ·»åŠ ç”¨æˆ·è®¤è¯
- å®ç°ç”¨æˆ·çº§åˆ«çš„æ£€æŸ¥ç‚¹éš”ç¦»
- æ”¯æŒå¤šç§Ÿæˆ·éƒ¨ç½²

### 2. é«˜çº§è¯„åˆ†

- æ”¯æŒæ›´å¤šé¢˜å‹ï¼ˆå¤šé€‰é¢˜ã€åˆ¤æ–­é¢˜ï¼‰
- ä½¿ç”¨æ›´å…ˆè¿›çš„è¯­ä¹‰ç›¸ä¼¼åº¦è¯„åˆ†
- æä¾›æ›´è¯¦ç»†çš„é”™é¢˜åˆ†æ

### 3. è‡ªé€‚åº”éš¾åº¦

- æ ¹æ®ç”¨æˆ·è¡¨ç°åŠ¨æ€è°ƒæ•´é¢˜ç›®éš¾åº¦
- å®ç°ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„
- è®°å½•å­¦ä¹ è¿›åº¦å’Œæˆé•¿æ›²çº¿

### 4. åˆ†å¸ƒå¼éƒ¨ç½²

- ä½¿ç”¨ Redis ä½œä¸ºæ£€æŸ¥ç‚¹å­˜å‚¨
- æ”¯æŒæ°´å¹³æ‰©å±•
- å®ç°è´Ÿè½½å‡è¡¡

## ğŸ“š å‚è€ƒèµ„æº

- [LangGraph å®˜æ–¹æ–‡æ¡£](https://docs.langchain.com/oss/python/langgraph/)
- [LangGraph Checkpointing](https://docs.langchain.com/oss/python/langgraph/persistence)
- [LangGraph Interrupts](https://docs.langchain.com/oss/python/langgraph/interrupts)
- [LangGraph Streaming](https://docs.langchain.com/oss/python/langgraph/streaming)

## ğŸ“ æ€»ç»“

ç¬¬ 3 é˜¶æ®µæˆåŠŸå®ç°äº†ä¸€ä¸ªå®Œæ•´çš„ã€ç”Ÿäº§çº§çš„å­¦ä¹ å·¥ä½œæµç³»ç»Ÿã€‚å…³é”®æˆå°±ï¼š

âœ… å®Œå…¨åŸºäº LangChain v1.0.3 å’Œ LangGraph
âœ… å®ç°äº†æ‰€æœ‰è®¡åˆ’çš„æ ¸å¿ƒç‰¹æ€§
âœ… æä¾›äº†å®Œæ•´çš„ API å’Œ CLI
âœ… ç¼–å†™äº†è¯¦ç»†çš„æµ‹è¯•å’Œæ–‡æ¡£
âœ… ä¸ºç¬¬ 4 é˜¶æ®µï¼ˆDeepAgentsï¼‰æ‰“ä¸‹äº†åšå®åŸºç¡€

ä¸‹ä¸€æ­¥å°†è¿›å…¥ç¬¬ 4 é˜¶æ®µï¼Œå®ç°æ›´å¤æ‚çš„æ·±åº¦ç ”ç©¶å·¥ä½œæµã€‚

